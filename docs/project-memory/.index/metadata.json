[
  {
    "sessionId": "S-2026-02-18-0340-initial-build",
    "title": "Initial RAG service build â€” project scaffolding and full implementation",
    "file": "docs/project-memory/sessions/S-2026-02-18-0340-initial-build.md",
    "date": "2026-02-18",
    "author": "Claude + David",
    "goal": "Build the complete RAG service from the design doc: FastAPI server with document ingestion, vector search, drag-and-drop UI, and Docker packaging.",
    "keywords": [
      "1-distance",
      "13-slim",
      "20-30ms",
      "2026-02-17-rag-service-design",
      "384-dim",
      "57ms",
      "actual",
      "add",
      "adding",
      "all-minilm-l6-v2",
      "app",
      "approved",
      "assistant",
      "avoids",
      "batch",
      "beautifulsoup",
      "build",
      "calculation",
      "changes",
      "character",
      "chunk",
      "chunker",
      "claude",
      "complete",
      "config",
      "context",
      "core",
      "cosine",
      "counting",
      "create",
      "created",
      "createelement",
      "dark",
      "decision",
      "decisions",
      "defaults",
      "delete",
      "dependencies",
      "dependency",
      "design",
      "dev",
      "directly",
      "distance",
      "distances",
      "doc",
      "docker",
      "docker-compose",
      "dockerfile",
      "docs",
      "document"
    ]
  },
  {
    "sessionId": "S-2026-02-18-0549-rag-tool-integration",
    "title": "Add RAG Tool to Voice Assistant",
    "file": "docs/project-memory/sessions/S-2026-02-18-0549-rag-tool-integration.md",
    "date": "2026-02-18",
    "author": "Claude",
    "goal": "Connect the RAG service (running on localhost:8100 with 690 indexed GitHub repo docs) to the voice assistant by adding a `RAGTool` that the LLM can call to answer questions about the user's projects.",
    "keywords": [
      "2-second",
      "about",
      "add",
      "added",
      "adding",
      "already",
      "answer",
      "assistant",
      "balances",
      "base",
      "basetool",
      "block",
      "both",
      "call",
      "changes",
      "chosen",
      "class",
      "clear",
      "config",
      "configurable",
      "connect",
      "context",
      "create",
      "created",
      "davidbmar",
      "decisions",
      "default",
      "dependencies",
      "distinguish",
      "docs",
      "document",
      "documents",
      "don",
      "down",
      "endpoint",
      "enough",
      "env",
      "explicit",
      "failure",
      "fast",
      "field",
      "follow",
      "following",
      "formats",
      "framework",
      "github",
      "goal",
      "graceful",
      "http",
      "httpx"
    ]
  },
  {
    "sessionId": "S-2026-02-18-0639-upgrade-embedding-model",
    "title": "Upgrade RAG embedding model to nomic-embed-text-v1.5",
    "file": "docs/project-memory/sessions/S-2026-02-18-0639-upgrade-embedding-model.md",
    "date": "2026-02-18",
    "author": "Claude",
    "goal": "Replace `all-MiniLM-L6-v2` (384-dim) with `nomic-ai/nomic-embed-text-v1.5` (768-dim) to improve retrieval quality, especially for code/technical content. Add task prefix support and auto-migration for dimension changes.",
    "keywords": [
      "384-dim",
      "43-0",
      "768-dim",
      "add",
      "added",
      "all-minilm-l6-v2",
      "already",
      "auto-migration",
      "batch",
      "because",
      "build",
      "bumps",
      "changes",
      "clean",
      "code",
      "config",
      "constructor",
      "content",
      "context",
      "create",
      "cron",
      "current",
      "custom",
      "decisions",
      "default",
      "dep",
      "detect",
      "detection",
      "dict",
      "dim",
      "dimension",
      "doc",
      "docker-compose",
      "dockerfile",
      "don",
      "download",
      "drop",
      "drops",
      "dynamic",
      "einops",
      "embed",
      "embedder",
      "embedding",
      "env",
      "especially",
      "exact",
      "existing",
      "full",
      "get",
      "goal"
    ]
  }
]
